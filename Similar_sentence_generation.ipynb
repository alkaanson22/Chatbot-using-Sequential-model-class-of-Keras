{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Similar sentence generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icW-VW6vJKPK",
        "outputId": "0b7a984f-bb50-4aa3-e328-4b3e80769ed4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmtOKWJHsk-R",
        "outputId": "3dee2631-15d5-4634-db7c-2f804d701078"
      },
      "source": [
        "import gensim\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove_input_file = '/content/drive/MyDrive/Colab Notebooks/glove.6B/glove.6B.100d.txt'\n",
        "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FuuNkUztP2-"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "filename = 'glove.6B.100d.txt.word2vec'\n",
        "glove_model=gensim.models.KeyedVectors.load_word2vec_format(filename,binary=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhe4rm35EckR",
        "outputId": "9cadd93a-470a-4d22-effd-a08cccd089ad"
      },
      "source": [
        "print(glove_model.most_similar(positive=['australia'], topn=10))\n",
        "print(glove_model.similarity('woman', 'man'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('zealand', 0.9042125344276428), ('england', 0.7858782410621643), ('australian', 0.7696145176887512), ('britain', 0.7670673131942749), ('canada', 0.7569618821144104), ('africa', 0.7522280216217041), ('scotland', 0.7264114618301392), ('wales', 0.7209109663963318), ('india', 0.704209566116333), ('indies', 0.6983797550201416)]\n",
            "0.8323495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ4p5lwQE3y5"
      },
      "source": [
        "vocab = glove_model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfdDQQBNFH3N",
        "outputId": "0b4b6268-53fe-4a0d-c898-c66f67bda2ad"
      },
      "source": [
        "len(vocab.vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkpBs8RnFLlk",
        "outputId": "56465d9c-9601-4946-daa4-a260e8c789b9"
      },
      "source": [
        "import nltk \n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english')) \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uebLO9rFFTXg"
      },
      "source": [
        "def fetch_pos_identity(pos_tag):\n",
        "    \n",
        "    '''\n",
        "    This method returns\n",
        "    \n",
        "    1. 'np' for proper nouns, 'n' for all other nouns\n",
        "    \n",
        "    2. 'a' for adjectives\n",
        "    \n",
        "    3. 'v' for verbs\n",
        "    \n",
        "    4. 'r' for adverbs\n",
        "    \n",
        "    5. None for all other tags\n",
        "    '''\n",
        "    \n",
        "    if pos_tag in ['NNP', 'NNPS']:\n",
        "        return 'np'\n",
        "    elif pos_tag in ['NN', 'NNS']:\n",
        "        return 'n'\n",
        "    elif pos_tag in ['JJ', 'JJR', 'JJS']:\n",
        "        return 'a'\n",
        "    elif pos_tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
        "        return 'v'\n",
        "    elif pos_tag in ['RB', 'RBR', 'RBS']:\n",
        "        return 'r'\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS-WxBHEFXra"
      },
      "source": [
        "def get_related_words(word, pos_tag, similarity_threshold):\n",
        "    \n",
        "    '''\n",
        "    This method returns most similar words to the word passed.\n",
        "    \n",
        "    args:\n",
        "    \n",
        "    word = input word\n",
        "    pos_tag = Simple POS tag of the word\n",
        "    similarity_threshold (float) = Value between 0 and 1. Indicates the similarity threshold to consider\n",
        "    \n",
        "    returns:\n",
        "    \n",
        "    a list of similar words, along with the original word\n",
        "    '''\n",
        "\n",
        "    # Lemmatize the word\n",
        "    word = lemmatizer.lemmatize(word, pos_tag)\n",
        "    synonyms = [word] \n",
        "    \n",
        "    \n",
        "    try:\n",
        "        vector_check = glove_model.get_vector(word)\n",
        "    except:\n",
        "        # If the word does not exist in the Glove model, return\n",
        "        return synonyms\n",
        "\n",
        "    for syn in wordnet.synsets(word): \n",
        "    \n",
        "        for l in syn.lemmas():\n",
        "        \n",
        "            try:\n",
        "            \n",
        "                if l.name() in synonyms:\n",
        "                    continue\n",
        "                \n",
        "                # Get the vector of the synonym\n",
        "                vector_prospect = glove_model.get_vector(l.name())\n",
        "                cosine_diff = vocab.cosine_similarities(vector_1=vector_check, vectors_all=[vector_prospect])\n",
        "\n",
        "                if cosine_diff > similarity_threshold:\n",
        "                    synonyms.append(l.name()) \n",
        "            \n",
        "            except:\n",
        "                \n",
        "                pass\n",
        "        \n",
        "            \n",
        "    return synonyms"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikXs2WIMFkmq"
      },
      "source": [
        "def get_next_position(total_synonym_array, position_array, last_position):\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    This method returns the next position of word replacement.\n",
        "    \n",
        "    args:\n",
        "    \n",
        "    total_synonym_array = Array containing the total length of synonyms\n",
        "    position_array = Array containing current positions\n",
        "    last_position_array = Integer\n",
        "    \n",
        "    returns:\n",
        "    \n",
        "    next position to be updated, -1 if all positions are exhausted\n",
        "    '''\n",
        "    new_pos = last_position\n",
        "    \n",
        "    for i in range(len(total_synonym_array)):\n",
        "        \n",
        "        # get a new position\n",
        "        new_pos = (new_pos + 1) % len(total_synonym_array)\n",
        "        \n",
        "        # if the new position is not good enough, fetch a new one\n",
        "        if position_array[new_pos] == -1 or position_array[new_pos] == total_synonym_array[new_pos]:\n",
        "            continue\n",
        "        else:\n",
        "            return new_pos\n",
        "    print(new_pos)\n",
        "    return -1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhZ1EgJdFoXn"
      },
      "source": [
        "def get_position_arrays(sentence_combination):\n",
        "    \n",
        "    '''\n",
        "    This is a utility method to get position arrays.\n",
        "    \n",
        "    args:\n",
        "    \n",
        "    sentence_combination = [[word], [word1, word2, ]]\n",
        "    \n",
        "    returns:\n",
        "    \n",
        "    two position arrays\n",
        "    '''\n",
        "    total_synonym_array = []\n",
        "    initial_position_array = []\n",
        "    \n",
        "    for each_word_array in sentence_combination:\n",
        "        length = len(each_word_array)\n",
        "        total_synonym_array.append(length)\n",
        "        if length == 1:\n",
        "            initial_position_array.append(-1)\n",
        "        else:\n",
        "            initial_position_array.append(0)\n",
        "    \n",
        "    return total_synonym_array, initial_position_array"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4rVIVRgFsjj"
      },
      "source": [
        "def provide_alternate_sentence(sentence, num_versions=1, max_changes=1, similarity_threshold=0.7, ignore_stopwords=True, ignore_proper_nouns=True):\n",
        "    \n",
        "    '''\n",
        "    This method returns an alternate version(s) of the sentence passed by replacing words with their closest synonyms.\n",
        "    \n",
        "    args:\n",
        "    \n",
        "    sentence (String) = the input sentence\n",
        "    num_versions (int) = the number of alternate versions required\n",
        "    max_changes (int) = the maximum number of changes between versions\n",
        "    similarity_threshold (float) = Value between 0 and 1. Indicates the similarity threshold to consider while replacing words\n",
        "    ignore_stopwords (bool) = If True, stopwords will not be considered for replacement\n",
        "    ignore_proper_nouns (bool) = If True, proper nouns will be ignored for replacement\n",
        "    \n",
        "    returns:\n",
        "    \n",
        "    list of alternate sentence(s)\n",
        "    '''\n",
        "    \n",
        "    alternate_sentences = []\n",
        "    \n",
        "    sentence_combination = []\n",
        "    \n",
        "    # split the sentence into words\n",
        "    words = sentence.split()\n",
        "    \n",
        "    # pos tag the sentence\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    \n",
        "    for each_word_pos in pos_tags:\n",
        "        \n",
        "        word = each_word_pos[0]\n",
        "        pos_tag = each_word_pos[1]\n",
        "        short_pos = fetch_pos_identity(pos_tag)\n",
        "        # ignore proper nouns\n",
        "        if ignore_proper_nouns and 'np' == short_pos:\n",
        "            sentence_combination.append([word])\n",
        "            continue\n",
        "        \n",
        "        # lemmatize the word\n",
        "        if short_pos is not None:\n",
        "            word_lemmatized = lemmatizer.lemmatize(word, short_pos)\n",
        "        else:\n",
        "            word_lemmatized = lemmatizer.lemmatize(word)\n",
        "        \n",
        "        # ignore stopwords\n",
        "        if ignore_stopwords and (word_lemmatized in stop_words or word in stop_words):\n",
        "            sentence_combination.append([word])\n",
        "            continue\n",
        "        \n",
        "        # if POS is noun, adj, adv, or verb - get similar words\n",
        "        if short_pos is not None:\n",
        "            sentence_combination.append(get_related_words(word, short_pos, similarity_threshold))\n",
        "        # else do nothing\n",
        "        else:\n",
        "            sentence_combination.append([word])\n",
        "            continue\n",
        "    \n",
        "    total_synonym_array, position_array = get_position_arrays(sentence_combination)\n",
        "    \n",
        "    total_combos_possible = 0\n",
        "    for some_value in total_synonym_array:\n",
        "        if some_value > 1:\n",
        "            total_combos_possible = total_combos_possible + some_value\n",
        "    total_combos_possible = total_combos_possible - 1\n",
        "    last_position = -1\n",
        "    \n",
        " \n",
        "    for i in range(num_versions):\n",
        "        if i >= total_combos_possible:\n",
        "            break\n",
        "        \n",
        "        # get the position to replace\n",
        "        position = get_next_position(total_synonym_array, position_array, last_position)\n",
        "\n",
        "        \n",
        "        if position == -1:\n",
        "            break\n",
        "        \n",
        "        alt_sentence = ''\n",
        "        counter = 0\n",
        "        for j in sentence_combination:\n",
        "            alt_sentence = alt_sentence + ' '\n",
        "            if counter == position:\n",
        "                alt_sentence = alt_sentence + j[position_array[position] + 1 ]\n",
        "                position_array[position] = position_array[position] + 1\n",
        "                \n",
        "                last_position = position\n",
        "                \n",
        "            else:\n",
        "                if position_array[counter] > -1:\n",
        "                    alt_sentence = alt_sentence + j[position_array[counter] - 1]\n",
        "                else:\n",
        "                    alt_sentence = alt_sentence + j[position_array[counter]]\n",
        "                \n",
        "            \n",
        "            counter = counter + 1\n",
        "        \n",
        "        alt_sentence = alt_sentence.strip()\n",
        "        alternate_sentences.append(alt_sentence)\n",
        "            \n",
        "    return alternate_sentences\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mnzGPS7GLA8",
        "outputId": "861a16d9-522f-40a3-8c0c-9f60f4e31af4"
      },
      "source": [
        "provide_alternate_sentence(\"Submission error encountered\", num_versions=3, similarity_threshold=0.60)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Submission mistake confrontation',\n",
              " 'Submission error clash',\n",
              " 'Submission fault encounter']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}