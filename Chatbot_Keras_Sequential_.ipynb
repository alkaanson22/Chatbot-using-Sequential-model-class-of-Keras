{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot-Keras/Sequential..ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmV1PBjiIwHP",
        "outputId": "7c986ea0-86e0-4e8a-e1fb-7d0f44a08c1e"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import nltk\n",
        "import tensorflow\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "import json\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epS5op9-NQMc",
        "outputId": "4c2498fe-6d42-47a9-8156-b819fb31e522"
      },
      "source": [
        "intents= json.loads(open('intents.json').read())\n",
        "print(\"Processing intents\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing intents\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYCQhPbgOOZb",
        "outputId": "a2d12671-f011-45b2-eef0-dc43a0aa5fd9"
      },
      "source": [
        "nltk.download('punkt')\n",
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?','!',',','.']\n",
        "for intent in intents['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    w= nltk.word_tokenize(pattern)\n",
        "    words.extend(w)\n",
        "    documents.append((w, intent['tag']))\n",
        "    if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n",
        "print(classes)\n",
        "print(documents)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['greetings', 'goodbye', 'upload', 'access', 'download', 'watch', 'update', 'badges']\n",
            "[(['hey'], 'greetings'), (['hello'], 'greetings'), (['hi', 'there'], 'greetings'), (['hi'], 'greetings'), (['haii'], 'greetings'), (['hai'], 'greetings'), (['Greetings'], 'greetings'), ([], 'greetings'), (['what', \"'s\", 'up', '?'], 'greetings'), (['c'], 'goodbye'), (['bye'], 'goodbye'), (['goodbye'], 'goodbye'), (['Thank', 'you', 'so', 'much', '.'], 'goodbye'), (['good', 'day'], 'goodbye'), (['farewell'], 'goodbye'), (['adieu'], 'goodbye'), (['bye'], 'goodbye'), (['thankyou'], 'goodbye'), (['thanku'], 'goodbye'), (['Ca', \"n't\", 'upload', 'home', 'work'], 'upload'), (['I', \"'m\", 'unable', 'to', 'upload', 'my', 'homework'], 'upload'), (['Not', 'able', 'to', 'submit', 'home', 'work'], 'upload'), (['I', \"'m\", 'unable', 'to', 'turn', 'in', 'my', 'homework'], 'upload'), (['I', 'ca', \"n't\", 'upload', 'my', 'assignments'], 'upload'), (['I', \"'m\", 'not', 'allowed', 'to', 'upload', 'my', 'homework'], 'upload'), (['Ca', \"n't\", 'upload', 'hw'], 'upload'), (['I', 'ca', \"n't\", 'submit', 'any', 'homework', '.'], 'upload'), (['I', 'ca', \"n't\", 'submit', 'my', 'assignments'], 'upload'), (['Not', 'able', 'to', 'submit', 'hw'], 'upload'), (['I', 'ca', \"n't\", 'submit', 'a', 'paper', '.'], 'upload'), (['I', 'ca', \"n't\", 'submit', 'my', 'papers'], 'upload'), (['Unable', 'to', 'upload'], 'upload'), (['it', 'displays', 'an', 'error', 'of', 'submission'], 'upload'), (['it', 'shows', 'submission', 'error'], 'upload'), (['Not', 'able', 'to', 'upload'], 'upload'), (['submission', 'error'], 'upload'), (['upload', 'error'], 'upload'), (['it', 'shows', 'a', 'missubmission'], 'upload'), (['It', 'points', 'to', 'a', 'submission', 'error'], 'upload'), (['it', 'shows', 'a', 'failure', 'of', 'submission', '.'], 'upload'), (['it', 'displays', 'an', 'upload', 'error', '.'], 'upload'), (['it', 'shows', 'a', 'loading', 'error'], 'upload'), (['It', 'indicates', 'upload', 'error'], 'upload'), (['No', 'way', 'to', 'submit', 'assignments', '.'], 'upload'), (['It', \"'s\", 'not', 'possible', 'to', 'submit', 'papers'], 'upload'), (['I', 'ca', \"n't\", 'do', 'homework'], 'upload'), (['How', 'to', 'access', 'skedu', 'in', 'computer', 'or', 'iphone'], 'access'), (['Unable', 'to', 'access', 'skedu', 'using', 'iphone'], 'access'), (['How', 'to', 'install', 'this', 'app', '?'], 'access'), (['Ca', \"n't\", 'get', 'to', 'skedu', 'using', 'iphone', '.'], 'access'), (['Skedu', 'can', 'not', 'be', 'accessed', 'using', 'iphone'], 'access'), (['No', 'access', 'to', 'skedu', 'using', 'the', 'iphone', '.'], 'access'), (['It', 'is', 'not', 'possible', 'to', 'access', 'skedu', 'using', 'the', 'iphone', '.'], 'access'), (['Not', 'able', 'to', 'access', 'skedu', 'using', 'iphone', '.'], 'access'), (['Unable', 'to', 'access', 'skedu', 'using', 'computer'], 'access'), (['Ca', \"n't\", 'access', 'skedu', 'via', 'computer', '.'], 'access'), (['Skedu', 'can', 'not', 'be', 'accessed', 'through', 'the', 'computer', '.'], 'access'), (['Ca', \"n't\", 'get', 'to', 'skedu', 'from', 'the', 'computer', '.'], 'access'), (['Unable', 'to', 'access', 'skedu', 'via', 'PC', '.'], 'access'), (['Ca', \"n't\", 'access', 'skedu', 'PC'], 'access'), (['No', 'access', 'to', 'skedu', 'from', 'the', 'personal', 'computer'], 'access'), (['No', 'access', 'to', 'skedu', 'from', 'the', 'PC'], 'access'), (['Ca', \"n't\", 'get', 'to', 'skedu', 'from', 'the', 'PC'], 'access'), (['How', 'to', 'reach', 'skedu', 'in', 'the', 'computer', 'or', 'iphone', '.'], 'access'), (['How', 'to', 'access', 'skedu', 'on', 'PC', 'or', 'iphone', '.'], 'access'), (['How', 'to', 'enter', 'skedu', 'into', 'the', 'computer', 'or', 'iphone', '.'], 'access'), (['How', 'do', 'I', 'get', 'the', 'Skedu', 'app', '?'], 'access'), (['How', 'to', 'download', 'skedu', 'app', '?'], 'access'), (['What', 'is', 'the', 'procedure', 'for', 'installing', 'the', 'Skedu', 'application', '?'], 'access'), (['How', 'do', 'I', 'get', 'the', 'Skedu', 'app', 'on', 'my', 'phone', '?'], 'access'), (['Link', 'to', 'download', 'skedu', 'app', '?'], 'access'), (['Where', 'can', 'I', 'get', 'the', 'Skedu', 'app', '?'], 'access'), (['Is', 'there', 'a', 'connection', 'to', 'the', 'Skedu', 'app', \"'s\", 'download', 'page', '?'], 'access'), (['Is', 'there', 'a', 'connection', 'to', 'download', 'the', 'Skedu', 'app', '?'], 'access'), (['download', 'skedu'], 'access'), (['download', 'skedu'], 'access'), (['how', 'to', 'get', 'this', 'application'], 'access'), (['Ca', \"n't\", 'download', 'videos'], 'download'), (['Videos', 'can', 'not', 'be', 'downloaded', '.'], 'download'), (['Videos', 'are', 'not', 'available', 'for', 'download', '.'], 'download'), (['Videos', 'did', 'not', 'update'], 'download'), (['Downloading', 'of', 'videos', 'is', 'not', 'possible', '.'], 'download'), (['It', 'is', 'not', 'possible', 'to', 'import', 'videos', '.'], 'download'), (['I', 'ca', \"n't\", 'seem', 'to', 'get', 'the', 'notes', 'to', 'download', '.'], 'download'), (['I', 'ca', \"n't\", 'get', 'my', 'notes', 'to', 'download', '.'], 'download'), (['I', 'ca', \"n't\", 'seem', 'to', 'get', 'any', 'notes', 'to', 'save', '.'], 'download'), (['Not', 'able', 'to', 'save', 'videos'], 'download'), (['Notes', 'are', 'not', 'being', 'downloaded', '.'], 'download'), (['Not', 'able', 'to', 'download', 'videos'], 'download'), (['Impossible', 'to', 'download', 'videos', '.'], 'download'), (['Videos', 'are', 'not', 'downloadable'], 'download'), (['No', 'video', 'download', 'possible', '.'], 'download'), (['Notes', 'wo', \"n't\", 'download'], 'download'), ([], 'download'), (['Ca', \"n't\", 'download', 'notes'], 'download'), (['Not', 'able', 'download', 'notes'], 'download'), (['Downloading', 'notes', 'is', \"n't\", 'working', '.'], 'download'), (['Notes', 'are', 'not', 'being', 'downloaded', '.'], 'download'), (['Notes', 'are', \"n't\", 'being', 'downloaded', '.'], 'download'), (['Unable', 'to', 'download', 'notes'], 'download'), (['Notes', 'are', 'not', 'able', 'to', 'be', 'downloaded', '.'], 'download'), (['I', 'had', 'trouble', 'downloading', 'my', 'notes', '.'], 'download'), (['Downloading', 'notes', 'was', 'a', 'challenge', '.'], 'download'), (['I', 'was', 'having', 'trouble', 'downloading', 'videos', '.'], 'download'), (['Downloading', 'videos', 'was', 'a', 'challenge'], 'download'), (['unable/', 'not', 'able', 'to', 'download', 'notes'], 'download'), (['Notes', 'could', 'not', 'be', 'downloaded'], 'download'), (['unable/', 'not', 'able', 'to', 'download', 'videos'], 'download'), (['Having', 'difficulties', 'downloading', 'notes'], 'download'), (['videos', 'are', 'difficult', 'to', 'download'], 'download'), (['Videos', 'or', 'notes', 'are', 'difficult', 'to', 'obtain', '.'], 'download'), (['Downloading', 'notes', 'is', 'problematic'], 'download'), (['Videos', 'are', 'not', 'available', 'for', 'download', '.'], 'download'), (['I', 'ca', \"n't\", 'download', 'today', \"'s\", 'English', 'class', 'video'], 'download'), (['I', \"'m\", 'unable', 'to', 'download', 'the', 'video', 'from', 'today', \"'s\", 'English', 'lesson', '.'], 'download'), (['The', 'video', 'from', 'today', \"'s\", 'English', 'class', 'is', 'not', 'available', 'for', 'download', '.'], 'download'), (['I', \"'m\", 'having', 'trouble', 'downloading', 'the', 'video', 'from', 'today', \"'s\", 'English', 'lesson', '.'], 'download'), (['I', 'downloaded', 'many', 'videos', 'from', 'skedu', 'but', 'I', 'ca', \"n't\", 'see', 'it', 'in', 'file', 'manager'], 'download'), (['I', 'downloaded', 'a', 'lot', 'of', 'videos', 'from', 'Skedu', ',', 'but', 'they', 'are', \"n't\", 'showing', 'up', 'in', 'my', 'file', 'manager', '.'], 'download'), (['I', \"'ve\", 'downloaded', 'a', 'lot', 'of', 'videos', 'from', 'Skedu', ',', 'but', 'they', \"'re\", 'not', 'showing', 'up', 'in', 'my', 'file', 'manager', '.'], 'download'), (['Videos', 'I', \"'ve\", 'downloaded', 'are', \"n't\", 'showing', 'up', 'in', 'my', 'file', 'manager', '.'], 'download'), (['My', 'file', 'manager', 'does', 'not', 'display', 'downloaded', 'videos', '.'], 'download'), (['Ca', \"n't\", 'watch', 'videos', 'in', 'skedu'], 'watch'), (['In', 'Skedu'], 'watch'), (['I', \"'m\", 'unable', 'to', 'watch', 'videos', '.'], 'watch'), (['In', 'Skedu', ',', 'I', \"'m\", 'unable', 'to', 'view', 'videos', '.'], 'watch'), (['Having', 'difficulty', 'viewing', 'videos'], 'watch'), (['videos', 'are', 'difficult', 'to', 'view'], 'watch'), (['Having', 'difficulties', 'viewing', 'videos'], 'watch'), (['unable', 'to', 'watch', 'video'], 'watch'), (['not', 'able', 'to', 'watch', 'videos'], 'watch'), (['trouble', 'watching', 'videos'], 'watch'), (['Videos', 'wo', \"n't\", 'play'], 'watch'), (['In', 'Skedu', ',', 'it', \"'s\", 'difficult', 'to', 'watch', 'videos', '.'], 'watch'), (['Videos', 'in', 'skedu', 'are', 'difficult', 'to', 'watch', '.'], 'watch'), (['In', 'skedu', ',', 'I', 'am', 'having', 'trouble', 'viewing', 'videos', '.'], 'watch'), (['In', 'skedu', ',', 'there', 'are', 'several', 'issues', 'with', 'viewing', 'videos', '.'], 'watch'), (['issue', 'while', 'viewing', 'video'], 'watch'), (['I', \"'m\", 'unable', 'to', 'view', 'videos', 'on', 'the', 'smartphone', '.'], 'watch'), (['This', 'application', 'is', 'unable', 'to', 'play', 'videos', '.'], 'watch'), (['This', 'software', 'does', 'not', 'support', 'video', 'playback', '.'], 'watch'), (['This', 'software', 'is', \"n't\", 'capable', 'of', 'playing', 'videos', '.'], 'watch'), (['The', 'videos', 'in', 'this', 'app', 'do', 'not', 'work', 'for', 'me', '.'], 'watch'), (['I', 'am', 'unable', 'to', 'view', 'the', 'videos', 'on', 'skedu'], 'watch'), (['videos', 'wo', \"n't\", 'play'], 'watch'), (['How', 'to', 'update', 'Skedu'], 'update'), (['how', 'to', 'keep', 'skedu', 'up', 'to', 'date'], 'update'), (['what', 'is', 'the', 'best', 'way', 'to', 'keep', 'skedu', 'up', 'to', 'date', '?'], 'update'), (['How', 'do', 'I', 'get', 'this', 'app', 'updated', '?'], 'update'), (['how', 'will', 'this', 'app', 'be', 'updated'], 'update'), (['What', \"'s\", 'the', 'best', 'way', 'to', 'update', 'this', 'app', '?'], 'update'), (['How', 'do', 'I', 'update', 'this', 'app', '?'], 'update'), (['How', 'will', 'this', 'app', 'be', 'updated', '?'], 'update'), (['Is', 'there', 'a', 'way', 'to', 'update', 'skedu'], 'update'), (['Is', 'it', 'possible', 'to', 'update', 'skedu', '?'], 'update'), (['I', \"'d\", 'like', 'to', 'get', 'skedu', 'up', 'to', 'date', '.'], 'update'), (['Is', 'there', 'any', 'new', 'updates', '?'], 'update'), (['Is', 'there', 'a', 'new', 'version', 'of', 'the', 'software', 'available', '?'], 'update'), (['How', 'can', 'i', 'do', 'update', '?'], 'update'), (['Is', 'there', 'a', 'new', 'version', 'of', 'this', 'app', 'available', '?'], 'update'), (['Is', 'this', 'app', 'receiving', 'any', 'new', 'updates', '?'], 'update'), (['Is', 'this', 'app', 'seeing', 'any', 'new', 'updates', '?'], 'update'), (['How', 'do', 'I', 'get', 'the', 'most', 'up-to-date', 'features', 'in', 'this', 'app', '?'], 'update'), (['how', 'can', 'I', 'get', 'latest', 'features', 'in', 'this', 'app', '?'], 'update'), (['How', 'do', 'I', 'get', 'the', 'most', 'recent', 'features', 'in', 'this', 'app', '?'], 'update'), (['Are', 'there', 'any', 'new', 'updates', 'available', '?'], 'update'), (['Are', 'there', 'any', 'new', 'skedu', 'updates', 'available', '?'], 'update'), (['Is', 'skedu', 'receiving', 'any', 'new', 'updates', '?'], 'update'), (['Are', 'there', 'any', 'new', 'skedu', 'updates', '?'], 'update'), (['How', 'can', 'I', 'get', 'Skedu', 'badges', '?'], 'badges'), (['What', 'is', 'the', 'best', 'way', 'to', 'obtain', 'Skedu', 'badges', '?'], 'badges'), (['What', 'is', 'the', 'best', 'way', 'for', 'me', 'to', 'obtain', 'Skedu', 'badges', '?'], 'badges'), (['How', 'to', 'collect', 'Skedu', 'badges', '?'], 'badges'), (['What', 'is', 'the', 'best', 'way', 'to', 'collect', 'Skedu', 'badges', '?'], 'badges'), (['How', 'will', 'Skedu', 'badges', 'be', 'collected', '?'], 'badges'), (['How', 'do', 'I', 'gather', 'Skedu', 'badges', '?'], 'badges'), (['I', 'need', 'skedu', 'badges'], 'badges'), (['I', \"'m\", 'looking', 'for', 'skedu', 'badges', '.'], 'badges'), (['Skedu', 'bades', 'are', 'what', 'I', \"'m\", 'looking', 'for', '.'], 'badges'), (['I', 'want', 'skedu', 'bades', '.'], 'badges'), (['how', 'do', 'I', 'obtain', 'my', 'bades'], 'badges'), (['in', 'search', 'of', 'my', 'badges'], 'badges'), (['What', 'should', 'I', 'do', 'in', 'order', 'to', 'obtain', 'skedu', 'badges', '?'], 'badges'), (['What', 'am', 'I', 'supposed', 'to', 'do', 'in', 'order', 'to', 'obtain', 'skedu', 'badges', '?'], 'badges'), (['How', 'do', 'I', 'obtain', 'skedu', 'badges', '?'], 'badges'), (['Is', 'it', 'possible', 'to', 'obtain', 'skedu', 'badges', '?'], 'badges'), (['Is', 'it', 'possible', 'to', 'obtain', 'skedu', 'badges', 'in', 'some', 'way', '?'], 'badges'), (['What', 'steps', 'should', 'I', 'take', 'to', 'get', 'badges', '?'], 'badges'), (['What', 'should', 'I', 'do', 'in', 'order', 'to', 'obtain', 'badges', '?'], 'badges'), (['How', 'will', 'I', 'qualify', 'to', 'get', 'skedu', 'badges', '?'], 'badges'), (['How', 'to', 'meet', 'the', 'requirements', 'for', 'earning', 'skedu', 'batches', '?'], 'badges'), (['How', 'will', 'I', 'win', 'skedu', 'batches', '?'], 'badges'), (['How', 'to', 'win', 'batches', '?'], 'badges'), (['What', 'are', 'the', 'methods', 'for', 'winning', 'badges', '?'], 'badges'), (['What', 'are', 'the', 'strategies', 'for', 'winning', 'badges', '?'], 'badges')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S43nBeUdQ5RN",
        "outputId": "de1a64bf-64c1-4325-9a05-d83ca69f6869"
      },
      "source": [
        "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words] \n",
        "words= sorted(list(set(words)))\n",
        "classes = sorted(list(set(classes)))\n",
        "print(classes)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['access', 'badges', 'download', 'goodbye', 'greetings', 'update', 'upload', 'watch']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIkU1bx_ebkU",
        "outputId": "2a6a33b0-9214-4a02-b67e-8ca07dd930e5"
      },
      "source": [
        "print (len(documents), \"documents\")\n",
        "print (len(classes), \"classes\", classes)\n",
        "print (len(words), \"Unique stemmed words\", words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "195 documents\n",
            "8 classes ['access', 'badges', 'download', 'goodbye', 'greetings', 'update', 'upload', 'watch']\n",
            "178 Unique stemmed words [\"'d\", \"'m\", \"'re\", \"'s\", \"'ve\", 'a', 'abl', 'access', 'adieu', 'allow', 'am', 'an', 'any', 'ap', 'apply', 'ar', 'assign', 'avail', 'bad', 'badg', 'batch', 'be', 'being', 'best', 'but', 'bye', 'c', 'ca', 'can', 'cap', 'challeng', 'class', 'collect', 'comput', 'connect', 'could', 'dat', 'day', 'did', 'difficul', 'difficult', 'display', 'do', 'doe', 'download', 'earn', 'engl', 'ent', 'er', 'fail', 'farewel', 'feat', 'fil', 'for', 'from', 'gath', 'get', 'good', 'goodby', 'greet', 'had', 'hai', 'hav', 'hello', 'hey', 'hi', 'hom', 'homework', 'how', 'hw', 'i', 'import', 'imposs', 'in', 'ind', 'instal', 'into', 'iphon', 'is', 'issu', 'it', 'keep', 'latest', 'lesson', 'lik', 'link', 'load', 'look', 'lot', 'man', 'many', 'me', 'meet', 'method', 'missubmit', 'most', 'much', 'my', \"n't\", 'nee', 'new', 'no', 'not', 'obtain', 'of', 'on', 'or', 'ord', 'pag', 'pap', 'pc', 'person', 'phon', 'play', 'playback', 'point', 'poss', 'problem', 'proc', 'qual', 'reach', 'rec', 'receiv', 'requir', 'sav', 'search', 'see', 'seem', 'sev', 'should', 'show', 'skedu', 'smartphon', 'so', 'softw', 'som', 'step', 'strategies', 'submit', 'support', 'suppos', 'tak', 'thank', 'thanku', 'thankyou', 'the', 'ther', 'they', 'thi', 'through', 'to', 'today', 'troubl', 'turn', 'un', 'unable/', 'up', 'up-to-date', 'upd', 'upload', 'us', 'vert', 'via', 'video', 'view', 'want', 'was', 'watch', 'way', 'what', 'wher', 'whil', 'wil', 'win', 'with', 'wo', 'work', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-aC6_EwTvng"
      },
      "source": [
        "training = []\n",
        "output = []\n",
        "\n",
        "output_empty = [0] * len(classes)\n",
        "for doc in documents:\n",
        "    bag = []\n",
        "    pattern_words = doc[0]\n",
        "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "    training.append([bag, output_row])\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "\n",
        "# create train and test lists\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jWYCJeIaNMG"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import SGD\n",
        "import random"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jauBqIWIq4fb",
        "outputId": "53d9b656-1f81-4f90-981b-595f76cc2a1a"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "\n",
        "    # Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "    # fitting and saving the model\n",
        "hist=model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
        "model.save('chatbot_model.h5',hist)\n",
        "\n",
        "print(\"model created\")\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 0s 752us/step - loss: 2.0491 - accuracy: 0.1892\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 0s 862us/step - loss: 1.6854 - accuracy: 0.3768\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 0s 766us/step - loss: 1.2982 - accuracy: 0.5967\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 0s 903us/step - loss: 0.9996 - accuracy: 0.6077\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 0s 876us/step - loss: 0.6923 - accuracy: 0.7373\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 0s 804us/step - loss: 0.6133 - accuracy: 0.7712\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 0s 734us/step - loss: 0.4767 - accuracy: 0.8184\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 0s 774us/step - loss: 0.3901 - accuracy: 0.8871\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 0s 770us/step - loss: 0.3929 - accuracy: 0.8896\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 0s 802us/step - loss: 0.2916 - accuracy: 0.9094\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 0s 789us/step - loss: 0.3239 - accuracy: 0.9117\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.2998 - accuracy: 0.8933\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 0s 731us/step - loss: 0.2037 - accuracy: 0.9445\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 0s 861us/step - loss: 0.2512 - accuracy: 0.9006\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 0s 894us/step - loss: 0.1974 - accuracy: 0.9323\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 0s 761us/step - loss: 0.1649 - accuracy: 0.9403\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 0s 890us/step - loss: 0.1507 - accuracy: 0.9571\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 0s 817us/step - loss: 0.2118 - accuracy: 0.9656\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9541\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 0s 815us/step - loss: 0.1650 - accuracy: 0.9367\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 0s 998us/step - loss: 0.1567 - accuracy: 0.9542\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 0s 925us/step - loss: 0.2339 - accuracy: 0.9377\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9651\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 0s 719us/step - loss: 0.1246 - accuracy: 0.9793\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 0s 797us/step - loss: 0.0872 - accuracy: 0.9838\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 0s 828us/step - loss: 0.1000 - accuracy: 0.9797\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 0s 816us/step - loss: 0.0903 - accuracy: 0.9943\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9593\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 0s 879us/step - loss: 0.0977 - accuracy: 0.9687\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.9789\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 0s 767us/step - loss: 0.0873 - accuracy: 0.9841\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 0s 782us/step - loss: 0.0893 - accuracy: 0.9808\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 0s 729us/step - loss: 0.0636 - accuracy: 0.9921\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 0s 928us/step - loss: 0.1012 - accuracy: 0.9593\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 0s 758us/step - loss: 0.0675 - accuracy: 0.9845\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 0s 718us/step - loss: 0.0760 - accuracy: 0.9924\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 0s 785us/step - loss: 0.0676 - accuracy: 0.9856\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 0s 779us/step - loss: 0.0893 - accuracy: 0.9810\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 0s 728us/step - loss: 0.1024 - accuracy: 0.9790\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 0s 852us/step - loss: 0.0890 - accuracy: 0.9665\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 0s 819us/step - loss: 0.0364 - accuracy: 0.9912\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 0s 891us/step - loss: 0.1158 - accuracy: 0.9650\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 0s 863us/step - loss: 0.0586 - accuracy: 0.9837\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9857\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 0s 900us/step - loss: 0.0659 - accuracy: 0.9927\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 0s 845us/step - loss: 0.1265 - accuracy: 0.9775\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 0s 815us/step - loss: 0.0533 - accuracy: 0.9816\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 0s 764us/step - loss: 0.0250 - accuracy: 0.9921\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 0s 785us/step - loss: 0.0728 - accuracy: 0.9818\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 0s 788us/step - loss: 0.0459 - accuracy: 0.9933\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9864\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 0s 803us/step - loss: 0.0456 - accuracy: 0.9826\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 0s 801us/step - loss: 0.0420 - accuracy: 0.9845\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 0s 844us/step - loss: 0.0362 - accuracy: 0.9884\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 0s 766us/step - loss: 0.0549 - accuracy: 0.9858\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 0s 999us/step - loss: 0.0571 - accuracy: 0.9827\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 0s 915us/step - loss: 0.0214 - accuracy: 0.9973\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 0s 819us/step - loss: 0.0336 - accuracy: 0.9966\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 0s 737us/step - loss: 0.0555 - accuracy: 0.9717\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 0s 845us/step - loss: 0.0401 - accuracy: 0.9812\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 0s 854us/step - loss: 0.0240 - accuracy: 0.9946\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 0s 891us/step - loss: 0.0282 - accuracy: 0.9943\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 0s 821us/step - loss: 0.0375 - accuracy: 0.9942\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 0s 846us/step - loss: 0.0222 - accuracy: 0.9920\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 0s 844us/step - loss: 0.0387 - accuracy: 0.9977\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 0s 928us/step - loss: 0.0191 - accuracy: 0.9941\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 0s 819us/step - loss: 0.0448 - accuracy: 0.9855\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 0s 862us/step - loss: 0.0283 - accuracy: 0.9987\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 0s 952us/step - loss: 0.0294 - accuracy: 0.9956\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9902\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 0s 888us/step - loss: 0.0402 - accuracy: 0.9867\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 0s 792us/step - loss: 0.0506 - accuracy: 0.9831\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 0s 834us/step - loss: 0.0238 - accuracy: 0.9949\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 0s 821us/step - loss: 0.0650 - accuracy: 0.9840\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 0s 728us/step - loss: 0.0216 - accuracy: 0.9968\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 0s 860us/step - loss: 0.0541 - accuracy: 0.9811\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 0s 916us/step - loss: 0.0312 - accuracy: 0.9958\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 0s 761us/step - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 0s 859us/step - loss: 0.0092 - accuracy: 0.9987\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 0s 836us/step - loss: 0.0272 - accuracy: 0.9945\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 0s 816us/step - loss: 0.0240 - accuracy: 0.9976\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 0s 881us/step - loss: 0.0255 - accuracy: 0.9970\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 0s 917us/step - loss: 0.0260 - accuracy: 0.9874\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 0s 814us/step - loss: 0.0261 - accuracy: 0.9933\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 0s 759us/step - loss: 0.0489 - accuracy: 0.9704\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 0s 764us/step - loss: 0.0573 - accuracy: 0.9855\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 0s 911us/step - loss: 0.0417 - accuracy: 0.9832\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 0s 754us/step - loss: 0.0436 - accuracy: 0.9738\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 0s 820us/step - loss: 0.0329 - accuracy: 0.9966\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 0s 816us/step - loss: 0.0242 - accuracy: 0.9888\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9836\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.9920\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 0s 916us/step - loss: 0.0481 - accuracy: 0.9891\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 0s 829us/step - loss: 0.0174 - accuracy: 0.9897\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 0s 960us/step - loss: 0.0370 - accuracy: 0.9922\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 0s 798us/step - loss: 0.0219 - accuracy: 0.9926\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 0s 878us/step - loss: 0.0274 - accuracy: 0.9916\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 0s 775us/step - loss: 0.0104 - accuracy: 0.9982\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 0s 765us/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 0s 839us/step - loss: 0.0272 - accuracy: 0.9891\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 0s 752us/step - loss: 0.0081 - accuracy: 0.9993\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 0s 890us/step - loss: 0.0068 - accuracy: 0.9986\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 0.9996\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 0s 879us/step - loss: 0.0114 - accuracy: 0.9986\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 0s 874us/step - loss: 0.0295 - accuracy: 0.9963\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 0s 822us/step - loss: 0.0126 - accuracy: 0.9973\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 0s 891us/step - loss: 0.0203 - accuracy: 0.9996\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 0s 853us/step - loss: 0.0328 - accuracy: 0.9848\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 0s 899us/step - loss: 0.0535 - accuracy: 0.9786\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 0s 923us/step - loss: 0.0342 - accuracy: 0.9757\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 0s 741us/step - loss: 0.0157 - accuracy: 0.9944\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 0s 778us/step - loss: 0.0153 - accuracy: 0.9977\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9914\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 0s 819us/step - loss: 0.0131 - accuracy: 0.9993\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 0s 881us/step - loss: 0.0230 - accuracy: 0.9932\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 0s 833us/step - loss: 0.0178 - accuracy: 0.9947\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 0s 883us/step - loss: 0.0129 - accuracy: 0.9977\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 0s 766us/step - loss: 0.0493 - accuracy: 0.9825\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 0s 847us/step - loss: 0.0297 - accuracy: 0.9800\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9898\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 0s 862us/step - loss: 0.0215 - accuracy: 0.9981\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 0s 856us/step - loss: 0.0376 - accuracy: 0.9922\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 0s 824us/step - loss: 0.0324 - accuracy: 0.9879\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 0s 876us/step - loss: 0.0082 - accuracy: 0.9997\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 0s 921us/step - loss: 0.0096 - accuracy: 0.9961\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 0s 797us/step - loss: 0.0100 - accuracy: 0.9996\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 0s 831us/step - loss: 0.0091 - accuracy: 0.9996\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 0s 878us/step - loss: 0.0224 - accuracy: 0.9941\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 0s 863us/step - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 0s 826us/step - loss: 0.0626 - accuracy: 0.9788\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 0s 774us/step - loss: 0.0103 - accuracy: 0.9966\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 0s 770us/step - loss: 0.0352 - accuracy: 0.9761\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 0s 758us/step - loss: 0.0192 - accuracy: 0.9979\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 0s 819us/step - loss: 0.0347 - accuracy: 0.9832\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 0s 831us/step - loss: 0.0227 - accuracy: 0.9982\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 0s 871us/step - loss: 0.0138 - accuracy: 0.9979\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 0s 792us/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 0s 900us/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 0s 755us/step - loss: 0.0077 - accuracy: 0.9981\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 0s 896us/step - loss: 0.0512 - accuracy: 0.9810\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 0s 807us/step - loss: 0.0099 - accuracy: 0.9955\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 0s 831us/step - loss: 0.0116 - accuracy: 0.9982\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 0s 807us/step - loss: 0.0100 - accuracy: 0.9975\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 0s 767us/step - loss: 0.0231 - accuracy: 0.9882\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 0s 884us/step - loss: 0.0107 - accuracy: 0.9987\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 0s 881us/step - loss: 0.0178 - accuracy: 0.9949\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 0s 893us/step - loss: 0.0166 - accuracy: 0.9968\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 0s 806us/step - loss: 0.0167 - accuracy: 0.9958\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 0s 766us/step - loss: 0.0160 - accuracy: 0.9955\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 0s 812us/step - loss: 0.0291 - accuracy: 0.9945\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9695\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 0s 863us/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 0s 842us/step - loss: 0.0227 - accuracy: 0.9850\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 0s 819us/step - loss: 0.0189 - accuracy: 0.9922\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 0s 810us/step - loss: 0.0520 - accuracy: 0.9836\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 0s 755us/step - loss: 0.0230 - accuracy: 0.9909\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 0s 779us/step - loss: 0.0082 - accuracy: 0.9997\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 0s 851us/step - loss: 0.0413 - accuracy: 0.9881\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 0s 847us/step - loss: 0.0270 - accuracy: 0.9789\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 0s 876us/step - loss: 0.0143 - accuracy: 0.9963\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 0s 855us/step - loss: 0.0210 - accuracy: 0.9851\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.9908\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 0s 812us/step - loss: 0.0117 - accuracy: 0.9975\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 0s 902us/step - loss: 0.0196 - accuracy: 0.9874\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 0s 995us/step - loss: 0.0344 - accuracy: 0.9735\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 0s 846us/step - loss: 0.0220 - accuracy: 0.9984\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 0s 821us/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 0s 855us/step - loss: 0.0164 - accuracy: 0.9941\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 0s 798us/step - loss: 0.0511 - accuracy: 0.9833\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.9965\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 0s 935us/step - loss: 0.0286 - accuracy: 0.9849\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 0s 862us/step - loss: 0.0228 - accuracy: 0.9932\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 0.9975\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 0s 839us/step - loss: 0.0100 - accuracy: 0.9995\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 0s 824us/step - loss: 0.0080 - accuracy: 0.9948\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 0s 864us/step - loss: 0.0189 - accuracy: 0.9989\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 0s 976us/step - loss: 0.0183 - accuracy: 0.9979\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 0s 834us/step - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 0s 829us/step - loss: 0.0328 - accuracy: 0.9842\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 0s 849us/step - loss: 0.0129 - accuracy: 0.9908\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9955\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 0s 888us/step - loss: 0.0213 - accuracy: 0.9869\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 0s 787us/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 0s 962us/step - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 0s 966us/step - loss: 0.0239 - accuracy: 0.9952\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 0s 911us/step - loss: 0.0088 - accuracy: 0.9962\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 0s 759us/step - loss: 0.0253 - accuracy: 0.9946\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 0s 753us/step - loss: 0.0081 - accuracy: 0.9975\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 0s 845us/step - loss: 0.0445 - accuracy: 0.9860\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 0s 808us/step - loss: 0.0525 - accuracy: 0.9775\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 0s 954us/step - loss: 0.0174 - accuracy: 0.9882\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 0s 880us/step - loss: 0.0364 - accuracy: 0.9838\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 0s 856us/step - loss: 0.0174 - accuracy: 0.9909\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 0s 903us/step - loss: 0.0228 - accuracy: 0.9886\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9726\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 0s 906us/step - loss: 0.0269 - accuracy: 0.9909\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 0s 994us/step - loss: 0.0046 - accuracy: 0.9993\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 0s 825us/step - loss: 0.0210 - accuracy: 0.9878\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 0s 840us/step - loss: 0.0175 - accuracy: 0.9995\n",
            "model created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyLHKAK8giz2"
      },
      "source": [
        "pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open( \"training_data\", \"wb\" ) )"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z4iPSQGg4sW",
        "outputId": "024e33ed-2f6e-439f-86e8-173f2be290e6"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "print(\"Loading Pickle.....\")\n",
        "data = pickle.load( open( \"training_data\", \"rb\" ) )\n",
        "words = data['words']\n",
        "classes = data['classes']\n",
        "train_x = data['train_x']\n",
        "train_y = data['train_y']\n",
        "\n",
        "with open('intents.json') as json_data:\n",
        "    intents = json.load(json_data)\n",
        "\n",
        "model=load_model('chatbot_model.h5')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Pickle.....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY0692ihimgD",
        "outputId": "66d2422d-1714-4735-b03e-1e5fe30c658c"
      },
      "source": [
        "def clean_up_sentence(sentence):\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "def bow(sentence, words, show_details=False):\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    bag = [0]*len(words)\n",
        "    for s in sentence_words:\n",
        "        for i,w in enumerate(words):\n",
        "            if w == s:\n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % w)\n",
        "    return(np.array(bag))\n",
        "\n",
        "ERROR_THRESHOLD = 0.25\n",
        "print(\"ERROR_THRESHOLD = 0.25\")\n",
        "\n",
        "def classify(sentence):\n",
        "    results = model.predict(np.array([bow(sentence, words)]))[0]\n",
        "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append((classes[r[0]], r[1])) \n",
        "    return return_list\n",
        "\n",
        "def response(sentence, userID='123', show_details=False):\n",
        "    results = classify(sentence)\n",
        "    if results:\n",
        "        while results:\n",
        "            for i in intents['intents']:\n",
        "                if i['tag'] == results[0][0]:\n",
        "                    return random.choice(i['responses'])\n",
        "\n",
        "            results.pop(0)\n",
        "            "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR_THRESHOLD = 0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y53--_B57-H8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b64062e-edf4-4322-a3ac-5b85560ff908"
      },
      "source": [
        "flag= True\n",
        "while (flag==True) :\n",
        "  input_data=input(\"You: \")\n",
        "  input_data= input_data.lower()\n",
        "  if input_data not in ['bye','goodbye','quit']:\n",
        "    answer = response(input_data)\n",
        "    print(\"Bot:\", answer)\n",
        "  else:\n",
        "    flag=False\n",
        "    print(\"Bot: Bye! take care\")\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You: Hey\n",
            "Bot: how can we help you today\n",
            "You: Trouble uploading homework\n",
            "Bot: Please verify your Internet connection and retry.\n",
            "You: How to get this app?\n",
            "Bot: Please use this link to get skedu in computer or iphone, **http://www.jpnme.com/Common**\n",
            "You: How will I win skedu badges?\n",
            "Bot: For getting badges, you should do the activities regularly and try to perform well\n",
            "You: Facing issues watching videos\n",
            "Bot: please check your internet connection and try again\n",
            "You: Any new updates for this app?\n",
            "Bot: A new update to our SkEdu application is available in your playstore. If updation not available in your playstore please uninstall old SkEdu application and install our new version.\n",
            "You: Thankyou\n",
            "Bot: Have a great day!\n",
            "You: Bye\n",
            "Bot: Bye! take care\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}